# vtkVrui

This framework allows you to use VTK with Vrui. It uses the VTK
capbility to render into an existing OpenGL context. Since VRUI
provides an OpenGL context that anything could technically rendered
into, one only needs to get VTK to render into the context provided by
VRUI instead of using its own render windows. In earlier versions of
VTK, this required the use of render passes. This approach lets one
pick which render passes to run and then execute this set of render
passes. This would then issue the necessary OpenGL commands to render
into the existing context. While a working a solution, this tended to
be sensitive to what algorithms in VTK one wanted to use. For example,
there is a dedicated render pass for volumetric algorithm which has to
be selected if volume rendering was going to be used.

Since version 6, VTK provides the <em>vtkExternalOpenGLRenderer</em> and
<em>vtkExternalOpenGLRenderWindow</em> classes specifically for the
purpose to render into existing OpenGL contexts. This made this
significantly more stable and reliable. In addition, the coded needed
to make this work became shorter and much simpler. It essentially
follows the traditional pipeline setup with VTK but instead of using
the traditional render windows and renderers
<em>vtkExternalOpenGLRenderer</em> and
<em>vtkExternalOpenGLRenderWindow</em> are used.

As always with Vrui, one has to pay attention to how things are
rendered to make sure any store content, such as textures and display
lists, is available on the specific graphics card. This is especially
important for CAVE-type systems or any system that relies on multipipe
rendering, i.e. any system that uses more than one computer to drive
the displays or systems that rely on multiple graphics cards used per
computer. The DIVE system utilizes both of these mechanisms and as
such is especially sensitive to this issue. This then requires the
proper use of the dataItem in Vrui so that the textures are transfered
and graphics content is rendered into each graphics card as otherwise
some areas of the display system would not be able to show the
rendered content at all. This requires that the VTK rendering is
entirely handled within the dataItem and as a result one has to make
sure that any necessary files are available at each rendering
node. However, this is typically the requirement when using other
rendering libraries combined with VRUI as well.

In addition, support for touch-based devices is provided with this
framework. The <em>TouchNavigationTool</em> class is loosely based on
the <em>MouseNavigationTool</em> provided by VRUI. It assumes that a
link in <em>/dev/touch</em> points to the proper event input device for
the touchad or touchscreen. In order to support touch devices in other
VRUI-based applications, one only needs to copy the
<em>TouchNavigationTool</em> class into the project and initialize the
touch tool. A factory for initializing the tool is already in place so
all one has to do is to call the <em>createTouchTool</em> method in the
<em>TouchNavigationTool</em>.

The <em>TouchNavigationTool</em> will then create a background thread in
which it continuously processes the input device file for any
potentail input. The implementation supports multitouch devices. One
of our touch screens supports up to ten finger touch. The
<em>TouchNavigationTool</em> tracks the positions of as many fingers as
are supported by the device up to a maximum of twenty. Whenever the
driver detects a change in the position where a finger is touching the
screen, an event is generated by the driver with the updated
coordinates. The <em>TouchNavigationTool</em> then keeps track of all
fingers and their current coordinates.

Once the finger positions are tracked, the <em>TouchNavigationTool</em>
implements different modes for panning, zooming, and rotation based on
the number of fingers touching the screen. This could obviously be
adjusted based on the needs of the specific applications. With
one-finger touch, the <em>TouchNavigationTool</em> allows the user to
rotate the view. This follows the same mechanism as the mouse rotation
in VRUI so that it automatically rotates around the visible center. It
should be noted that the visible center may vary greatly depending on
the display system. In a desktop environment it would be the position
that relates to the center of the screen. In a CAVE-type environment,
this will usually be the center of the entire display system.

With two fingers touching the screen or device, zoom and rotation is
implemented similar to how map applications on cell phones work,
i.e. a pinch-type zoom mechanism and a rotation around the z-axis when
the fingers rotate on the screen uniformly. Whenever three fingers
touch, the view is panned in the direction in which the fingers
move. This typically provides a quite intuitive input paradigm,
especially since most users are used to interacting with cell phones
which provide similar interaction styles.

# License
This code is provided under the GNU General Public License
